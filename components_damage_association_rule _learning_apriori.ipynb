{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apyori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#CONNECTION TO SQL SERVER\n",
    "\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "\n",
    "server = 'fill'\n",
    "database = 'fill'\n",
    "username = 'fill'\n",
    "password = 'fill'   \n",
    "driver= '{SQL Server}'\n",
    "\n",
    "database = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = database.cursor()\n",
    "\n",
    "#SQL QUERY\n",
    "query = '''blank  '''\n",
    "df = pd.read_sql(query, database)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_list = df.groupby(df.FFA_TestSum_ReqId.values).agg(list).to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in array_list:\n",
    "   print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust according to data imported\n",
    "data = df\n",
    "data = data[['Result1','Result2','Result3','Result4','Result5']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data \n",
    "transactions = []\n",
    "for i in range(0, 213):    #correct to numbers of row from your dataset\n",
    "  transactions.append([str(dataset.values[i,j]) for j in range(0, 4)])  #choose number of max columns, place max column as a first one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from apyori import apriori\n",
    "rules = apriori(transactions = transactions, min_support = 0.012, min_confidence = 0.2, min_lift =3, min_length=2, max_length=2) #refer to me for metrics adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(rules)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(results):\n",
    "    lhs         = [tuple(result[2][0][0])[0] for result in results]\n",
    "    rhs         = [tuple(result[2][0][1])[0] for result in results]\n",
    "    supports    = [result[1] for result in results]\n",
    "    confidences = [result[2][0][2] for result in results]\n",
    "    lifts       = [result[2][0][3] for result in results]\n",
    "    return list(zip(lhs, rhs, supports, confidences, lifts))\n",
    "resultsinDataFrame = pd.DataFrame(inspect(results), columns = ['Left Hand Side', 'Right Hand Side', 'Support', 'Confidence', 'Lift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsinDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultsinDataFrame.nlargest(n = 10, columns = 'Lift') #grupowanie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#EXPORT TO SQL\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "#SAME CONNECTION\n",
    "server = 'fill'\n",
    "database = 'fill'\n",
    "username = 'fill'\n",
    "password = 'fill'   \n",
    "driver= '{SQL Server}'\n",
    "database = pyodbc.connect('DRIVER='+driver+';SERVER='+server+';PORT=1433;DATABASE='+database+';UID='+username+';PWD='+ password)\n",
    "cursor = database.cursor()\n",
    "\n",
    "\n",
    "#NEW Way of exporting\n",
    "#Insert Dataframe into SQL Server:\n",
    "for index, row in resultsinDataFrame.iterrows():\n",
    "    #adjust query below! - according to database table structure\n",
    "    cursor.execute(\"INSERT INTO NLP_test.TargetTable1 (processed_date, ProductName, [lineNo], review_id, sentiment, key_point) values(?,?,?,?,?,?)\", row.processed_date, row.ProductName, row.lineNo, row.review_id, row.sentiment, row.key_point)\n",
    "database.commit()\n",
    "cursor.close()\n",
    "\n",
    "print('execution stopped')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
